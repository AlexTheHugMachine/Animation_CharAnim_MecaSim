
/*! \addtogroup intrort principes du lancer de rayons

Un pipeline graphique permet de calculer la couleur des pixels d'une image représentant une scène 3d éclairée par une ou plusieurs sources de lumières.
Le pipeline openGL basé sur la rasterization / fragmentation est _une_ solution particulière. On peut résumer son fonctionnement :

\code
zbuffer[]= max
image[]= noir

pour chaque triangle
        transformer les sommets du triangle dans le repère projectif de la camera
        si une partie du triangle est visible dans l''image (ou dans le frustum de la camera)
            transformer les sommets dans le repere de l''image
            pour chaque pixel de l''image
                si le centre du pixel est inclus dans le triangle
                    interpoler les attributs des sommets
                    interpoler la profondeur
                    calculer la couleur
                    si profondeur < zbuffer[pixel]
                        image[pixel]= couleur
                        zbuffer[pixel]= profondeur
\endcode

ou en gros 
\code
zbuffer[]= max;

pour chaque triangle
    pour chaque pixel
        si profondeur < zbuffer[pixel]
        zbuffer[pixel]= profondeur
\endcode

à la fin du parcours, tous les pixels contiennent la profondeur du triangle le plus proche de la camera ainsi que sa couleur.

le lancer de rayon fonctionne dans l'autre sens :
\code
rayons[]
pour chaque pixel
    rayons[pixel]= rayon passant par le centre du pixel

zbuffer[]= max
image[]= noir
pour chaque rayon
    pour chaque triangle
        si le rayon touche le triangle
            si profondeur < zbuffer[rayon]
                interpoler les attributs des sommets
                calculer la couleur
                image[rayon]= couleur
                zbuffer[rayon]= profondeur
\endcode

à première vue, les 2 solutions ne sont pas très différentes. Pourtant, il y a une différence fondamentale, le lancer de rayons fonctionne pour un ensemble 
de rayons quelconque. Dans l'exemple ci-dessus, les 2 images seront identiques. Mais on peut facilement créer de nouveaux rayons pour tester la visibilité des
sources de lumière et ajouter très simplement les ombres dans l'image, ce qui est plus difficile à faire avec openGL, par exemple. 

Une autre différence importante est ce que l'on peut calculer l'intersection d'un rayon avec d'autres objets que des triangles : des spheres, des cubes, 
des plans, des cylindres, des cones, des tores, des fractales, des champs de distances, des fonctions implicites, etc. sans avoir à trianguler la surface de ces 
objets. Par contre, il faudra écrire les différentes fonctions d'intersections.

# rayon ?

Un rayon est une droite dans l'espace (de la scène, par exemple) qui passe par le centre d'un pixel dans l'image. Mais il faut connaitre au moins 2 points pour 
représenter une droite. lesquels ? L'idée est que le rayon est l'ensemble des points de la scène qui se projettent sur le centre du pixel. 

Quelles sont les coordonnées du centre d'un pixel dans le repère de la scène ? Il suffit de se rappeller que l'on peut transformer des coordonnées du repère 
image vers le repère de la scène en utilisant les transformations inverses des transformations standards. 
si on connait des coordonnées \f$ p_{scene} \f$ dans le repère de la scène, on peut écrire :
\f[
q_{image} = Image \times Projection \times View \times p_{scene}
\f]
et
\f[
p_{scene} = ( Image \times Projection \times View )^{-1} \times q_{image}
\f]

Quelles sont les coordonnées d'un pixel dans le repère \f$ Image \f$ ? On connait directement x et y, il ne reste plus que z ? Par définition, z = 0 
sur le plan proche du frustum de la camera et z = 1 sur le plan far du frustum. repassez dans le cours d'intro sur les transformations si ce n'est pas 
clair.

Résultat, on peut calculer les coordonnées de 2 points sur le rayon : x, y sur le plan near (z = 0), et x, y sur le plan far (z = 1) :
\f[
origine_{scene} = ( Image \times Projection \times View )^{-1} \times \begin{bmatrix} x \\ y \\ 0 \end{bmatrix}\\
extremité_{scene} = ( Image \times Projection \times View )^{-1} \times \begin{bmatrix} x \\ y \\ 1 \end{bmatrix}\\
\f]

On peut donc représenter le rayon par les 2 points : origine et extremité. Mais en général, pour calculer les intersections avec les objets, on utilise plutot une 
autre convention : origine et direction. direction est le vecteur entre l'origine et l'extremité \f$ direction = extremité - origine \f$.

_remarque :_ on connait un autre point sur le rayon, c'est le centre de projection de la camera, ou la position de la camera. Les coordonnées sont (0, 0, 0) 
dans le repère camera :
\f[
origine_{scene} = ( Image \times Projection )^{-1} \times \begin{bmatrix} 0 \\ 0 \\ 0 \end{bmatrix}\\
\f]

# intersection ?

Il ne reste plus qu'à trouver comment calculer l'intersection d'un rayon / d'une droite avec les objets qui composent la scène.

Il faut exprimer le fait qu'une intersection représente un point du rayon et un point de l'objet. permière question, comment représenter un point sur le rayon ?
la solution classique utilise la forme paramétrique des droites : \f$ p(t) = origine + t \cdot direction \f$, \f$ t \f$ identifie un point sur la droite / le rayon, la 
position du point sur la droite.

## plan
comment décrire l'ensemble de points sur un plan ? il existe de nombreuses manières, mais l'idée est de choisir une représentation qui permet d'écrire le calcul 
de l'intersection comme la recherche du zero d'une fonction.

On peut représenter un plan par un point \f$ a \f$ et une normale \f$ \vec{n} \f$, et déterminer l'ensemble des points \f$ p \f$ appartenant au plan comme les 
zeros de la forme implicite : 
\f[
\vec{n} \cdot \vec{ap} = 0
\f]

_remarque :_ les points \f$ p \f$ sont sur le plan si les vecteurs \f$ \vec{ap} \f$ et \f$ \vec{n} \f$ sont perpendiculaires, leur produit scalaire est nul dans ce cas.

calculer l'intersection du rayon et du plan se resume à trouver le point du rayon \f$ p(t) \f$ qui se trouve aussi sur le plan. le point d'intersection vérifie 
les 2 propriétés en même temps :
\f[
\vec{n} \cdot \vec{a p(t)} = 0
\f]

_rappel :_ \f$ p(t) = o + t\vec{d} \f$ désigne un point du rayon.

il ne reste plus qu'à trouver quelle valeur de t vérifie ces conditions :
\f[
\begin{eqnarray*}
\vec{n} \cdot \vec{ap(t)} 				& = & 0\\
\vec{n} \cdot ((o + t \vec{d}) - a) 			& = & 0\\
\vec{n} \cdot ((o - a) + (t \vec{d})) 			& = & 0\\
\vec{n} \cdot (o - a) + \vec{n} \cdot (t \vec{d})	& = & 0\\
\vec{n} \cdot (o - a) + t (\vec{n} \cdot \vec{d}) 	& = & 0\\
                t (\vec{n} \cdot \vec{d}) 	& = & - \vec{n} \cdot (o - a)\\
                              t & = & \frac{- \vec{n} \cdot (o - a)}{\vec{n} \cdot \vec{d}}\\
                              t & = & \frac{\vec{n} \cdot (a - o)}{\vec{n} \cdot \vec{d}}\\
\end{eqnarray*}
\f]


_rappel :_ calcul avec des points, des vecteurs et des produits scalaires, cf [wikipedia](https://en.wikipedia.org/wiki/Dot_product#Properties)

on peut remarquer que, sans trop de surprise, un rayon intersecte toujours un plan, sauf lorsque le rayon est parallele au plan et que la direction du rayon 
et la normale du plan sont perpendiculaires.

Par contre, il ne faut pas oublier que l'on ne s'interresse qu'aux intersections se trouvant devant la camera, c'est à dire \f$ t > 0 \f$, il faut bien faire la 
différence entre les intersections de la droite et des objets testés et les intersections du rayon (la demi droite positive) avec les objets... 

## sphere

Pour une sphère de centre \f$ c \f$, et de rayon \f$ r \f$, même stratégie : les points de l'espace sont sur la sphère s'ils se trouvent à la bonne distance du 
centre :
\f[
\begin{eqnarray*}
| p - c | & = & r \\
| p - c | - r  & = & 0 \\
| p - c |^2 - r^2 & = & 0\\
(p - c) \cdot (p -  c) - r^2 & = & 0
\end{eqnarray*}
\f]

_rappel :_ on a utilisé une relation entre le produit scalaire et (le carré de) la longueur du vecteur : \f$ \vec{u} \cdot \vec{u} = |u|^2 \f$

il ne reste plus qu'à trouver la valeur de \f$ t \f$ pour que \f$ p(t) \f$, le point sur le rayon soit aussi sur la sphère :
\f[
\begin{eqnarray*}
(p(t) - c) \cdot (p(t) -  c) - r^2 & = & 0\\
(o + t\vec{d} - c) \cdot (o + t\vec{d} -  c) - r^2 & = & 0\\
((o - c) + t\vec{d}) \cdot ((o - c) + t\vec{d}) - r^2 & = & 0\\
(\vec{d} \cdot \vec{d}) t^2 + 2\vec{d} \cdot (o - c) t + (o - c) \cdot (o - c) - r^2 & = & 0\\
\end{eqnarray*}
\f]

il faut relire attentivement ce résultat, mais il est sous une forme assez simple au final :
\f[
\begin{eqnarray*}
a t^2 + b t + k & = & 0\\
a & = & \vec{d} \cdot \vec{d}\\
b & = & 2\vec{d} \cdot (o - c)\\
k & = & (o - c) \cdot (o - c) - r^2 
\end{eqnarray*}
\f]

il ne reste plus qu'à calculer les zeros du polynome : les détails sont sur [wikipedia](https://en.wikipedia.org/wiki/Quadratic_formula) et [ici](https://en.wikipedia.org/wiki/Quadratic_equation)
et ce résultat est assez intuitif : une droite peut passer à coté de la sphère, la toucher en un seul point, ou la traverser en 2 points.

si \f$ b^2 - 4ak > 0 \f$, les solutions s'écrivent :
\f[
\begin{eqnarray*}
t_1 & = & \frac{-b + \sqrt{b^2 - 4ak}}{2a}\\
t_2 & = & \frac{-b - \sqrt{b^2 - 4ak}}{2a}\\
\end{eqnarray*}
\f]

Par contre, il ne faut pas oublier que l'on ne veut que les intersections avec le rayon, pas les intersections avec la droite. il faut donc aussi vérifier le signe 
des solutions \f$ t_1 > 0 \f$ et \f$ t_2 > 0 \f$

__pour les curieux :__ on peut gagner pas mal de temps en ne calculant qu'une seule solution, et en normalisant \f$ \vec{d} \f$ à l'avance, 
\f$ | \vec{d} |= 1 \f$ et aussi \f$| \vec{d} |^2 =  \vec{d} \cdot \vec{d} = a = 1\f$. Selon le cas, on 
sait à l'avance que l'origine du rayon se trouve à l'exterieur de la sphère, et il suffit de calculer la plus petite racine \f$ > 0 \f$.

## triangle

Il y a plusieurs manières de faire ce calcul. par exemple, calculer l'intersection du rayon et du plan qui porte le triangle 
(représenté par un sommet du triangle et sa normale géométrique, \f$ a \f$ et \f$ \vec{n}= \vec{ab} \times \vec{ac} \f$, puis vérifier que le point du 
plan est aussi à l'intérieur du triangle. 

Il faut aussi se rappler que l'on veut les coordonnées barycentriques du point d'intersection pour obtenir les memes informations que la 
rasterization / fragmentation, mais surtout pour pouvoir interpoler les attibuts des sommets du triangle.

du coup, on peut représenter un point dans le plan du triangle \f$ abc \f$ à l'aide des coordonnées barycentriques : 
\f[
p(\alpha, \beta, \gamma) = \alpha a + \beta b + \gamma c
\f]
mais les points à l'intérieur du triangle vérifient quelques propriétés supplémentaires :
\f[
\begin{eqnarray*}
\alpha & >= & 0\\
\beta & >= & 0\\
\gamma & >= & 0\\
\alpha + \beta + \gamma & =& 1
\end{eqnarray*}
\f]

\f$ \alpha \f$ peut être recalculée en fonction des 2 autres : \f$ \alpha= 1 - \beta - \gamma \f$ et on utilise la forme simplifiée :
\f[ 
p(\beta, \gamma) = (1 - \beta - \gamma) a + \beta b + \gamma c
\f]

__remarque :__ il existe plusieurs conventions pour cette simplification, n'importe laquelle des 3 peut etre calculée implicitement.

il ne reste plus qu'à écrire qu'un point doit être en même temps sur le rayon et dans le triangle :
\f[
\begin{eqnarray*}
    p(t) & = & p(\beta, \gamma)\\
    o + t\vec{d} & = & (1 - \beta - \gamma) a + \beta b + \gamma c\\
    o + t\vec{d} & = & a + \beta (b - a) + \gamma (c - a)\\
    - t\vec{d} + \beta (b - a) + \gamma (c - a) & = & (o - a) \\
\end{eqnarray*}
\f]

on obtient un système linéaire, 3 équations et 3 inconnues (\f$ t, \beta, \gamma \f$), une solution élégante n'utilisant que des produits scalaires et vectoriels est proposée dans cet 
article : ["Fast, Minimum Storage Ray Triangle Intersection", T. Moller, B. Trumbore, 1997](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.124.8459&rep=rep1&type=pdf)

## cube 

\todo

# en pratique

Comment calculer une image avec du lancer de rayons et les triangles d'un Mesh ?


\code
int main( )
{
    const char *orbiter_filename= "cornell_orbiter.txt";
    const char *mesh_filename= "cornell.obj";
    
    // cree l'image resultat
    Image image(1024, 768);
    
    // charge une camera
    Orbiter camera;
    if(camera.read_orbiter(orbiter_filename) < 0)
        return 1;

    // charge des triangles
    Mesh mesh= read_mesh(mesh_filename);
    
    // recupere les triangles du mesh
    std::vector<Triangle> triangles;
    {
        int n= mesh.triangle_count();
        for(int i= 0; i < n; i++)
            triangles.emplace_back(mesh.triangle(i), i);
    }
    
    // recupere les transformations standards
    camera.projection(image.width(), image.height(), 45);
    Transform model= Identity();
    Transform view= camera.view();
    Transform projection= camera.projection();
    Transform viewport= camera.viewport();
    Transform inv= Inverse(viewport * projection * view * model);
    
    // c'est parti, parcours tous les pixels de l'image
    for(int y= 0; y < image.height(); y++)
    for(int x= 0; x < image.width(); x++)
    {
        // generer le rayon sur le centre du pixel (x, y)
        Point origine= inv(Point(x + .5f, y + .5f, 0));
        Point extremite= inv(Point(x + .5f, y + .5f, 1));
        Ray ray(origine, extremite);
        
        // calculer les intersections avec tous les triangles
        Hit hit;
        for(int i= 0; i < int(triangles.size()); i++)
        {
            if(Hit h= triangles[i].intersect(ray, hit.t))
                // ne conserve que l'intersection la plus proche de l'origine du rayon
                hit= h;
        }
        
        if(hit)
            // pixel rouge en cas d'intersection
            image(x, y)= Red();
    }
    
    // enregistre l'image
    write_image(image, "render.png");
    return 0;
}
\endcode

et voila, pas bien compliqué !! malgrè des explications un peu longues...

bon, afficher des pixels rouges, ne permet pas vraiment de vérifier que les intersections fonctionnent, il suffit de construire une couleur avec le résultat de 
l'intersection :
\code
if(hit)
    // coordonnees barycentriques de l'intersection
    image(x, y)= Color(1 - hit.u - hit.v, hit.u, hit.v);
\endcode

le sommet a des triangles apparait en rouge, le sommet b en vert et le sommet c en bleu...

<IMG SRC="rt_uvw.png" width="50%"> 

## matière diffuse, source de lumière, et lumière réfléchie...

pour calculer la couleur des pixels en fonction de la matière du triangle et de sa normale interpolée, il faut ajouter quelques éléments :
    - interpoler les normales des sommets du triangle en fonction des coordonnées de l'intersection,
    - recuperer la couleur diffuse de la matiere du triangle,
    - recuperer la position de la source de lumière,
    - calculer la lumière réfléchie vers la camera / l'origine du rayon.

pour interpoler la normale au point d'intersection en fonction des normales des sommets du triangle, il suffit de ré-utiliser les coordonnées barycentriques 
du point d'intersection avec le triangle, exactement comme le pipeline openGL :
\f[
\vec{n}(\beta, \gamma) = (1 - \beta - \gamma) \vec{n_a} + \beta \vec{n_b} + \gamma \vec{n_c}
\f]

\code
Vector normal( const Mesh& mesh, const Hit& hit )
{
    // recuperer le triangle complet dans le mesh
    const TriangleData& data= mesh.triangle(hit.triangle_id);
    // interpoler la normale avec les coordonnées barycentriques du point d'intersection
    float w= 1 - hit.u - hit.v;
    Vector n= w * data.na + hit.u * data.nb + hit.v * data.nc;
    return normalize(n);
}
\endcode

pour récupérer la couleur de la matière :
\code
Color diffuse_color( const Mesh& mesh, const Hit& hit )
{
    const Material& material= mesh.triangle_material(hit.triangle_id);
    return material.diffuse;
}
\endcode

pour trouver les sources de lumière, il faut parcourir les triangles du Mesh et vérifier si leur matière émet de la lumière. comme c'est un peu long, ce sera fait
une seule fois au début du programme :
\code
struct Source
{
    Point s;
    Color emission;
};

// recuperer les sources de lumière dans le mesh
std::vector<Source> sources;
int n= mesh.triangle_count();
for(int i= 0; i < n; i++)
{
    const Material& material= mesh.triangle_material(i);
    if(material.emission.r + material.emission.g + material.emission.b > 0)
    {
        // utiliser le centre du triangle comme source de lumière
        const TriangleData& data= mesh.triangle(i);
        Point p= (data.a + data.b + data.c) / 3;
        
        sources.push_back( { p, material.emission } );
    }
}
printf("%d sources\n", int(sources.size()));
assert(sources.size() > 0);
\endcode

il ne reste plus qu'à calculer la lumière réfléchie par une matière diffuse, comme dans le tp précédent (cf `lumière et matière`)
\code
if(hit)
{
    // position et emission de la source de lumiere
    Point s= sources[0].s;
    Color emission= sources[0].emission;

    // position du point d'intersection
    Point p= ray.o + hit.t * ray.d;
    // direction de p vers la source s
    Vector l= normalize(Vector(p, s));

    // interpoler la normale au point d'intersection
    Vector pn= normal(mesh, hit);
    // calculer la lumiere reflechie vers la camera / l'origine du rayon
    float cos_theta= std::abs(dot(pn, l));
    Color fr= diffuse_color(mesh, hit) / M_PI;
    
    Color color= emission * fr * cos_theta
    image(x, y)= color;
}
\endcode

et voila :
<IMG SRC="rt_diffuse.png" width="50%"> 

il ne reste plus qu'à ajouter les ombres...

_indication :_ il suffit de construire un rayon entre p et s, le point sur la source, et de vérifier qu'il n'y a __pas__ d'intersection entre eux, pour que la 
lumière arrive au point p, sinon p est à l'ombre...

<IMG SRC="rt_shadow.png" width="50%"> 

## et alors ?

et avec d'autres objets, qu'est ce qui change ? il faut écrire les fonctions d'intersection rayon / objet pour chaque cas.


## annexe 
il manque les définitions des structures Ray, Hit et Triangle :
\code

struct Ray
{
    Point o;            // origine
    Vector d;           // direction
    
    Ray( const Point& _o, const Point& _e ) :  o(_o), d(Vector(_o, _e)) {}
};

struct Hit
{
    float t;            // p(t)= o + td, position du point d'intersection sur le rayon
    float u, v;         // p(u, v), position du point d'intersection sur le triangle
    int triangle_id;    // indice du triangle dans le mesh
    
    // pas d'intersection
    Hit( ) : t(FLT_MAX), u(), v(), triangle_id(-1) {}   
    // intersection 
    Hit( const float _t, const float _u, const float _v, const int _id ) : t(_t), u(_u), v(_v), triangle_id(_id) {}
    
    // renvoie vrai si l'intersection est valide
    operator bool ( ) { return (triangle_id != -1); }
};

struct Triangle
{
    Point p;            // sommet a du triangle
    Vector e1, e2;      // aretes ab, ac du triangle
    int id;
    
    Triangle( const TriangleData& data, const int _id ) : p(data.a), e1(Vector(data.a, data.b)), e2(Vector(data.a, data.c)), id(_id) {}
    
    /* calcule l'intersection ray/triangle
        cf "fast, minimum storage ray-triangle intersection" 
        
        renvoie faux s'il n'y a pas d'intersection valide (une intersection peut exister mais peut ne pas se trouver dans l'intervalle [0 tmax] du rayon.)
        renvoie vrai + les coordonnees barycentriques (u, v) du point d'intersection + sa position le long du rayon (t).
        convention barycentrique : p(u, v)= (1 - u - v) * a + u * b + v * c
    */
    Hit intersect( const Ray &ray, const float tmax ) const
    {
        Vector pvec= cross(ray.d, e2);
        float det= dot(e1, pvec);
        
        float inv_det= 1 / det;
        Vector tvec(p, ray.o);
        
        float u= dot(tvec, pvec) * inv_det;
        if(u < 0 || u > 1) return Hit();        // pas d'intersection, u doit etre entre 0 et 1
        
        Vector qvec= cross(tvec, e1);
        float v= dot(ray.d, qvec) * inv_det;
        if(v < 0 || u + v > 1) return Hit();    // pas d'intersection, v doit etre entre 0 et 1-u pour que w= 1-u-v soit aussi entre 0 et 1
        
        float t= dot(e2, qvec) * inv_det;
        if(t < 0 || t > tmax) return Hit();     // pas d'intersection, t doit etre entre 0 et tmax
        
        return Hit(t, u, v, id);                // intersection valide p(u, v)= (1-u-v)*a + u*b + v*c
    }
};
\endcode

le code complet est dans tuto_rayons.cpp

# c'est trop lent !!



*/
