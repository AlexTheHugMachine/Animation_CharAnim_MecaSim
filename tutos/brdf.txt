
/*! \addtogroup brdf shader et brdf

# (toute) petite histoire des modèles de matières utilisés en synthèse.

physique :
- Lambert 1760 : matière diffuse opaque,
- Fresnel 1823 : réflexion et réfraction par une surface lisse, opaque ou transparente,
- Torrance - Sparrow 1967 : réflexion par une surface rugueuse : les microfacettes.

utilisation dans la communauté image :
- modèle diffus de Lambert ??
- Phong 1975 : reflet symétrique, 
- Blinn - Phong 1976 : reflet "réaliste", inspiré des microfacettes de Torrance - Sparrow 1967,
- [Cook - Torrance 1981](https://graphics.pixar.com/library/ReflectanceModel/index.html) : modèle à microfacettes dérivé de Torrance - Sparrow 1967, surface rugueuse opaque,
- [Walter 2007](https://www.cs.cornell.edu/~srm/publications/EGSR07-btdf.pdf) : reformulation du modèle de Cook - Torrance, utilisation de la distribution GGX et de sa normalisation exacte, surface rugueuse opaque ou transparente,
- [Burley 2012](https://blog.selfshadow.com/publications/s2012-shading-course/burley/s2012_pbs_disney_brdf_notes_v3.pdf) : comparaison mesures / modèles, reparamétrisation "intuitive" des paramètres, séparation des métaux des autres matières, modèle Disney,
- [Heitz 2014](http://jcgt.org/published/0003/02/03/) : normalisation, conservation de l'énergie et validation des modèles à microfacettes, [slides](http://jcgt.org/published/0003/02/03/presentation.pdf)
- [Burley 2015](https://blog.selfshadow.com/publications/s2015-shading-course/burley/s2015_pbs_disney_bsdf_notes.pdf) : simplification, intégration des validations de Heitz 2014, 

Le terme PBR vient des travaux de Walter et Burley, l'industrie a enfin compris les avantages de faire les choses correctement...

Tous les modèles de matières s'utilisent de la même manière. Ils permettent de connaitre la lumière réfléchie vers une direction, l'observateur, par exemple :
\f[L_r(p, \vec{o})= L_i(p, \vec{l}) f_r(\vec{l}, \vec{o}) \cos \theta_l \f]

La lumière  \f$ L_i(p, \vec{l}) \f$ arrive sur le point p depuis la direction \f$\vec{l}\f$ et le modèle de matière, la _brdf_ \f$f_r(\vec{l}, \vec{o})\f$ indique 
quelle quantité \f$L_r(p, \vec{o})\f$ est réfléchie par p dans la direction \f$\vec{o}\f$.

## premier shader : matière diffuse, modèle de Lambert

\f[ f_r(\vec{o}, \vec{l})= \frac{k}{\pi}\f]

_remarque :_ pourquoi le  \f$ \frac{1}{\pi} \f$ ? les modèles de matières doivent vérifier quelques propriétés. Les détails sont dans la partie modèles réalistes.

donc oui, ce "modèle" de réflexion est une constante k comprise entre 0 et 1 qui représente à quel point la matière réfléchit la lumière incidente. Et comme il est indépendant 
de la direction d'observation, la même quantité de lumière est réfléchie dans toutes les directions.

### et avec un shader ? comment on fait ?

on doit calculer :
\f[L_r(p, \vec{o})= L_i(p, \vec{l}) \frac{k}{\pi} \cos \theta_l \f]

il suffit de calculer \f$ \cos \theta_l \f$, le cosinus de l'angle entre la normale en p et la direction vers la lumière, et de se rappeler que les 
calculs sur les points et les vecteurs doivent se faire avec des coordonnées dans le même repère.

en résumé, il faut connaitre, dans le même repère : 
- p, la position du point éclairé,
-  \f$ \vec{n} \f$, la normale de la surface au point p,
-  \f$ \vec{o} \f$, la direction du point p vers l'observateur, la camera,
-  \f$ \vec{l} \f$, la direction du point p vers la source de lumière,
- k, la constante de modèle de réflexion.

premier constat, les normales et les positions doivent faire partie de la description des sommets de l'objet. elles sont donc accessibles par le vertex shader, 
mais pas directement par le fragment shader.

la position de la camera, la position de la source de lumière, son emission et la constante k, seront des `uniforms` du fragment shader.

__comment obtenir p et n dans le fragment shader ?__

il suffit de se rappeler que les sorties du vertex shader sont interpolées avant d'être accessibles par le fragment shader. l'interpolation des positions des sommets 
du triangle calcule, pour chaque pixel, la position dans l'espace du point du triangle se projettant sur le centre du pixel. pour les normales, il ne faut pas oublier 
que l'interpolation change la longueur des vecteurs.
le vertex shader déclare 2 sorties, des varyings : `out vec3 p; out vec3 n;` il ne reste plus qu'à calculer leurs coordonnées dans un repère commun...


_quel repère pour les calculs ?_ n'importe quel repère avant la projection : repère objet, scène ou camera. 
la projection ne préserve par les angles, et comme on doit en calculer plusieurs, autant choisir un repère dans lequel c'est simple à faire.

les exemples suivants font les calculs dans le repère du monde, mais ce n'est peut être pas le plus efficace. _pourquoi ?_

on suppose que l'on connait la position de la source et la position de la camera dans le repère du monde, donc pas de transformation. pour les sommets et les 
normales, par contre, on connait leur coordonnées dans le repère de l'objet, il faut donc les transformer, en utilisant la matrice `model`.

\code
#version 330

// vertex shader
in vec3 position;
in vec3 normal;

uniform mat4 mvpMatrix;
uniform mat4 modelMatrix;

out vec3 p;
out vec3 n;

void main( )
{
    gl_Position= mvpMatrix * vec4(position, 1);
    
    p= vec3(modelMatrix * vec4(position, 1));
    n= vec3(modelMatrix * vec4(normal, 0));
    
    /* remarque : il faudrait calculer :
        vec4 p4= modelMatrix * vec4(position, 1);
        vec4 n4= modelMatrix * vec4(normal, 0);
        p= p4.xyz / p4.w;
        n= n4.xyz;
        
        mais, comme il n'y a de projection dans la transformation utilisee, p4.w == 1 
        et comme normal est une direction n4.w == 0...
    */
    
    /* remarque : il pas necessaire d'utiliser une matrice homogene pour transformer un vecteur. on peut aussi ecrire :
        n= mat3(modelMatrix) * normal;
    */
}
\endcode

il ne reste plus qu'à écrire le fragment shader qui doit calculer les directions  \f$ \vec{o} \f$ et  \f$ \vec{l} \f$ et \f$ \cos \theta_l \f$ :
\code
#version 330

// fragment shader
in vec3 p;
in vec3 n;

uniform vec3 camera;
uniform vec3 source;
uniform vec3 emission;
uniform float k;

const float PI= 3.14159265359;

out vec4 fragment_color;
void main( )
{
    // directions 
    vec3 o= normalize(camera - p);
    vec3 l= normalize(source - p);
    // cos
    float cos_theta= dot(normalize(n), l);
    
    // brdf
    float fr= k / PI;
    vec3 color= emission * fr * cos_theta;
    
    fragment_color= vec4(color, 1);
}
\endcode

_une relation utile :_ \f$ \cos \angle(\vec{u}, \vec{v})= \frac{\vec{u} \cdot \vec{v}}{||\vec{u}|| \cdot ||\vec{v}||} \f$, ce qui s'écrit directement :
`float cos_theta= dot(normalize(u), normalize(v));`

_autre remarque :_ les normales devraient être transformées par une matrice différente de celles des sommets. dans les cas simples, lorsqu'il n'y a pas
d'étirement ou de changement d'échelle dans la transformation des sommets, les normales subissent la même transformation.
sinon Transform::normal() renvoie la transformation à utiliser sur les normales.

ce shader suppose que le flux émis par la source arrive intégralement en p, ce qui est faux, il manque un terme  \f$ 1 / ||\vec{l}||^2 \f$ et un 
cosinus si la source n'est pas un point. cf le cours simulation et integration numérique.

vous pouvez tester avec shader_kit, cf \ref shader_kit :\n
`bin/shader_kit tutos/brdf_lambert.glsl data/bigguy.obj`

<IMG SRC="shaderkit_lambert.png" width="50%">

## premier reflets : modèle de Blinn Phong

Comment reproduire le type de reflet que l'on peut observer dans cette [expérience](http://resources.mpi-inf.mpg.de/lighttransport/) ?
<table>
<tr> 
    <td> <IMG SRC="white-inset.png"> 
    <td> <IMG SRC="silver-inset.png"> 
    <td> <IMG SRC="mirror-inset.png"> 
</table>

Le modèle de Lambert, permet de reproduire le comportement de gauche, le modèle de Fresnel reproduit un miroir, le comportement de droite. Comment 
contrôler le reflet dans le cas intermédiaire ?

J. Blinn en 1976, reformule le modèle de B. Phong 1975 pour mieux reproduire l'étirement des reflets lorsque la lumière est incidente avec un angle 
important. L'idée est relativement simple : quelle devrait être la direction de la normale pour produire un reflet "miroir" entre les directions \f$ \vec{o} \f$ 
et \f$ \vec{l} \f$ ? 

réponse : \f$ \vec{h}= \frac{\vec{o} + \vec{l}}{|| \vec{o} + \vec{l} ||}\f$ puisque la direction \f$ \vec{o} \f$ devient symétrique de \f$ \vec{l} \f$ par rapport à \f$ \vec{h} \f$.
Et plus \f$ \vec{h} \f$ est loin de la normale en p, plus l'observateur est loin du reflet miroir de  \f$ \vec{l} \f$. Ne reste plus qu'une question, comment controler la taille, la concentration du reflet ?
Il fallait une fonction rapide à calculer (en 1976 les machines n'etaient pas tout à fait les mêmes...) et qui décroit plus ou moins vite vers 0 en fonction d'un paramètre... 

et c'est \f$ \cos^\alpha \theta_h \f$ qui à gagné. mais pas tout à fait :
<IMG SRC="cosn.png" width="30%">

l'exposant permet bien de controler la taille du reflet, la fonction décroit vers 0 plus ou moins vite, mais plus le reflet est petit, moins il est intense, ce qui est plutot génant...
la fonction doit vérifier une autre propriété : elle doit etre normalisée, son intégrale, pour \f$ \theta_h \in [0 \, \pi/2] \f$ doit être égale à 1, quelque soit la taille du reflet, la même quantité 
de lumière est réfléchie sur l'ensemble des directions : \f$ \frac{\alpha +1}{2\pi} \int \cos^\alpha \theta_h \, d\omega = 1\f$
<IMG SRC="cosnorm.png" width="30%">

Mais si on utilise cette fonction comme _brdf_, il se passe autre chose : la matière réfléchit plus de lumière qu'elle n'en reçoit... c'est encore un problème de normalisation. Il faut s'assurer que 
pour une direction \f$ \vec{l} \f$ la somme de la lumière réflechie \f$  f_r(\vec{l}, \vec{o}) \cos \theta_o \f$ est inférieure ou égale à 1 : 
\f[ \int f_r(\vec{l}, \vec{o}) \cos \theta_o d\omega_o = 1 \f]
_remarque :_ lorsqu'un modèle de matière vérifie cette condition de normalisation, on dit qu'il _conserve_ l'énergie.

Pour ce cas, il n'existe pas de solution parfaite, c'est un compromis, les calculs sont rapidement décrits par [F. Giesen](http://www.farbrausch.de/%7Efg/stuff/phong.pdf) et
fournissent un résultat simple :
\f[ f_r(\vec{o}, \vec{l})= \frac{\alpha+8}{8\pi} \cos^\alpha \theta_h\f]


et voila la quantité de lumière réfléchie en fonction de \f$ \theta_l \f$, pour les 3 versions : modèle diffus (courbe bleue), modèle normalisé (courbe rouge) et modèle conservatif (courbe verte) :
<IMG SRC="conservation.png" width="30%">

Ce modèle, Blinn - Phong normalisé, est très simple à calculer, se comporte correctement, mais l'intensité de ses reflets diminue lorsque l'incidence de la lumière augmente, ce qui ne correspond 
pas vraiment à ce que l'on peut observer dans la nature...

## reflets réalistes : modèle à microfacettes

Les modèles à microfacettes sont basés sur la physique des années 60. Leur première utilisation en image date de 1984 par Cook et Torrance qui travaillaient alors chez Pixar. Ce modèle a ensuite 
été utilisé pour produire les premiers court-métrages de Pixar.


*/
